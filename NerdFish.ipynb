{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgRJIPgJ8iTnGDzS0hnxu5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2494337a6c84aaeb62d8b63d3168321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58ef86774768410f8e7d2764d03d87c2",
              "IPY_MODEL_6967f74d3ec74b46b67a0efb15e6a3a2",
              "IPY_MODEL_915db24e8afa405f98134f2580ea82a4"
            ],
            "layout": "IPY_MODEL_f269fa190b0840edb95fad9c8fc88b71"
          }
        },
        "58ef86774768410f8e7d2764d03d87c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2c8d3853d284b3db7285b905c8a1cdf",
            "placeholder": "​",
            "style": "IPY_MODEL_9cf85325149b45d492c716e7a579bbfc",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "6967f74d3ec74b46b67a0efb15e6a3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbd5935e5d1d4419a7f74a0dc7ef341f",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_233a132ce6f14778a2b2390cc5bca3bd",
            "value": 7
          }
        },
        "915db24e8afa405f98134f2580ea82a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f99e99aac34405a3784354a7521a63",
            "placeholder": "​",
            "style": "IPY_MODEL_a8479035352b4b19801f704859069e84",
            "value": " 7/7 [00:18&lt;00:00,  2.52s/it]"
          }
        },
        "f269fa190b0840edb95fad9c8fc88b71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2c8d3853d284b3db7285b905c8a1cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cf85325149b45d492c716e7a579bbfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbd5935e5d1d4419a7f74a0dc7ef341f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "233a132ce6f14778a2b2390cc5bca3bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9f99e99aac34405a3784354a7521a63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8479035352b4b19801f704859069e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14c7eebf9a5c4789bbd2eb07d2bda8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d6a27ef86a948c0b107560d3536d6d8",
              "IPY_MODEL_36be9a304e2946f69d9132595f068369",
              "IPY_MODEL_cd9b1b28edc546688d1017bfe6e67b14"
            ],
            "layout": "IPY_MODEL_da63901213114aa0b635b71fa475acee"
          }
        },
        "3d6a27ef86a948c0b107560d3536d6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37749776f23a49aa9aba2377b280deab",
            "placeholder": "​",
            "style": "IPY_MODEL_6e30275963d74a879416cc9da148e3d7",
            "value": "100%"
          }
        },
        "36be9a304e2946f69d9132595f068369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_760782c16f3e4b079f12ffae242dcd99",
            "max": 37,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b273e2431ec34869a26c148dbbc89fc5",
            "value": 37
          }
        },
        "cd9b1b28edc546688d1017bfe6e67b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20a2f915e5d3475eb80d9a81add95868",
            "placeholder": "​",
            "style": "IPY_MODEL_4fc1f6d12fa443ba970682c2f5332010",
            "value": " 37/37 [00:05&lt;00:00,  6.81it/s]"
          }
        },
        "da63901213114aa0b635b71fa475acee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37749776f23a49aa9aba2377b280deab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e30275963d74a879416cc9da148e3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "760782c16f3e4b079f12ffae242dcd99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b273e2431ec34869a26c148dbbc89fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20a2f915e5d3475eb80d9a81add95868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fc1f6d12fa443ba970682c2f5332010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sortira/aiml-works/blob/main/NerdFish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nerdfish\n",
        "\n",
        "A tool for nerds to catfish using image filters, AI or non-AI"
      ],
      "metadata": {
        "id": "zN-MrKDXs0ZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random, cv2, torch\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import numpy as np\n",
        "from transformers import *\n",
        "from diffusers import StableDiffusionImg2ImgPipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AnXS-432tFHv",
        "outputId": "1e413b30-f377-428e-faaf-5bc82783072e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GroupViT models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version.Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n",
            "TAPAS models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version. Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(image, noise_factor=0.2):\n",
        "    np_image = np.array(image)\n",
        "    noise = np.random.normal(scale=noise_factor * 255, size=np_image.shape)\n",
        "    noisy_image = np_image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return Image.fromarray(noisy_image.astype(np.uint8))"
      ],
      "metadata": {
        "id": "AWqkoWXOs9Ty"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vintage(image):\n",
        "    width, height = image.size\n",
        "    pixels = image.load()\n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "            r, g, b = pixels[x, y]\n",
        "            tr = int(0.393 * r + 0.769 * g + 0.189 * b)\n",
        "            tg = int(0.349 * r + 0.686 * g + 0.168 * b)\n",
        "            tb = int(0.272 * r + 0.534 * g + 0.131 * b)\n",
        "            r, g, b = min(tr, 255), min(tg, 255), min(tb, 255)\n",
        "            pixels[x, y] = (r, g, b)\n",
        "    enhancer = ImageEnhance.Contrast(image)\n",
        "    image = enhancer.enhance(1.2)\n",
        "    return image"
      ],
      "metadata": {
        "id": "JJkprmgHtSQu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vignette(image):\n",
        "    width, height = image.size\n",
        "    cx, cy = width / 2, height / 2\n",
        "    strength = 0.5\n",
        "    vig_img = image.convert('RGBA')\n",
        "    pixels = vig_img.load()\n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "            d = ((x - cx) / cx) ** 2 + ((y - cy) / cy) ** 2\n",
        "            pixels[x, y] = tuple(int(v * (1 - strength * d)) for v in pixels[x, y])\n",
        "    return vig_img.convert('RGB')"
      ],
      "metadata": {
        "id": "wEzvNyOwtX8P"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scanlines(image, line_intensity=80, line_spacing=5):\n",
        "    width, height = image.size\n",
        "    pixels = image.load()\n",
        "\n",
        "    for y in range(0, height, line_spacing):\n",
        "        for x in range(width):\n",
        "            r, g, b = pixels[x, y]\n",
        "            pixels[x, y] = (max(r - line_intensity, 0), max(g - line_intensity, 0), max(b - line_intensity, 0))\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "Quo_Tk0wtb4Z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def colordistort(image, strength=20):\n",
        "    width, height = image.size\n",
        "    pixels = image.load()\n",
        "\n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "            r, g, b = pixels[x, y]\n",
        "            r = max(0, min(255, r + random.randint(-strength, strength)))\n",
        "            g = max(0, min(255, g + random.randint(-strength, strength)))\n",
        "            b = max(0, min(255, b + random.randint(-strength, strength)))\n",
        "            pixels[x, y] = (r, g, b)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "XPjEQW6vteIP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pixelate(image, pixel_size=9):\n",
        "    width, height = image.size\n",
        "    image = image.resize(\n",
        "        (width // pixel_size, height // pixel_size),\n",
        "        resample=Image.NEAREST\n",
        "    )\n",
        "    image = image.resize(\n",
        "        (width, height),\n",
        "        resample=Image.NEAREST\n",
        "    )\n",
        "    return image"
      ],
      "metadata": {
        "id": "bcUOgP9Jtks3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scratch(image, scratch_factor=0.08):\n",
        "    np_image = np.array(image)\n",
        "    height, width, _ = np_image.shape\n",
        "\n",
        "    for _ in range(int(scratch_factor * width * height)):\n",
        "        x = np.random.randint(0, width)\n",
        "        y = np.random.randint(0, height)\n",
        "        np_image[y, x] = [255, 255, 255]\n",
        "    return Image.fromarray(np_image)"
      ],
      "metadata": {
        "id": "jUCHEDiitmy-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def glitch(image, glitch_intensity=50, shift_max=15):\n",
        "    np_image = np.array(image)\n",
        "    height, width, _ = np_image.shape\n",
        "    for _ in range(glitch_intensity):\n",
        "        row = random.randint(0, height - 1)\n",
        "        shift = random.randint(-shift_max, shift_max)\n",
        "        np_image[row] = np.roll(np_image[row], shift, axis=0)\n",
        "        if random.random() < 0.5:\n",
        "            np_image[row] = np_image[row] + np.random.randint(-50, 50, np_image[row].shape)\n",
        "\n",
        "    np_image = np.clip(np_image, 0, 255)\n",
        "    return Image.fromarray(np_image.astype(np.uint8))"
      ],
      "metadata": {
        "id": "QWoH1CdStosh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rMgH3SZ0ttmR",
        "outputId": "2c35884f-a6f3-4e68-a25e-843f99377dd3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--openai--clip-vit-base-patch16/snapshots/57c216476eefef5ab752ec549e440a49ae4ae5f3/config.json\n",
            "`text_config` is `None`. Initializing the `CLIPTextConfig` with default values.\n",
            "`vision_config` is `None`. initializing the `CLIPVisionConfig` with default values.\n",
            "Model config CLIPConfig {\n",
            "  \"architectures\": [\n",
            "    \"CLIPModel\"\n",
            "  ],\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"logit_scale_init_value\": 2.6592,\n",
            "  \"model_type\": \"clip\",\n",
            "  \"projection_dim\": 512,\n",
            "  \"text_config\": {\n",
            "    \"bos_token_id\": 0,\n",
            "    \"dropout\": 0.0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"model_type\": \"clip_text_model\"\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"vision_config\": {\n",
            "    \"dropout\": 0.0,\n",
            "    \"model_type\": \"clip_vision_model\",\n",
            "    \"patch_size\": 16\n",
            "  }\n",
            "}\n",
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--openai--clip-vit-base-patch16/snapshots/57c216476eefef5ab752ec549e440a49ae4ae5f3/pytorch_model.bin\n",
            "Instantiating CLIPTextModel model under default dtype torch.float32.\n",
            "Instantiating CLIPVisionModel model under default dtype torch.float32.\n",
            "Attempting to create safetensors variant\n",
            "All model checkpoint weights were used when initializing CLIPModel.\n",
            "\n",
            "All the weights of CLIPModel were initialized from the model checkpoint at openai/clip-vit-base-patch16.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPModel for predictions without further training.\n",
            "loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--openai--clip-vit-base-patch16/snapshots/57c216476eefef5ab752ec549e440a49ae4ae5f3/preprocessor_config.json\n",
            "size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}, {'max_height', 'max_width'}), got 224. Converted to {'shortest_edge': 224}.\n",
            "crop_size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}, {'max_height', 'max_width'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
            "Image processor CLIPImageProcessor {\n",
            "  \"crop_size\": {\n",
            "    \"height\": 224,\n",
            "    \"width\": 224\n",
            "  },\n",
            "  \"do_center_crop\": true,\n",
            "  \"do_convert_rgb\": true,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.48145466,\n",
            "    0.4578275,\n",
            "    0.40821073\n",
            "  ],\n",
            "  \"image_processor_type\": \"CLIPImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.26862954,\n",
            "    0.26130258,\n",
            "    0.27577711\n",
            "  ],\n",
            "  \"resample\": 3,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"shortest_edge\": 224\n",
            "  }\n",
            "}\n",
            "\n",
            "Attempting to convert .bin model on the fly to safetensors.\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--openai--clip-vit-base-patch16/snapshots/57c216476eefef5ab752ec549e440a49ae4ae5f3/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--openai--clip-vit-base-patch16/snapshots/57c216476eefef5ab752ec549e440a49ae4ae5f3/merges.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--openai--clip-vit-base-patch16/snapshots/57c216476eefef5ab752ec549e440a49ae4ae5f3/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--openai--clip-vit-base-patch16/snapshots/57c216476eefef5ab752ec549e440a49ae4ae5f3/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--openai--clip-vit-base-patch16/snapshots/57c216476eefef5ab752ec549e440a49ae4ae5f3/tokenizer_config.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "Processor CLIPProcessor:\n",
            "- image_processor: CLIPImageProcessor {\n",
            "  \"crop_size\": {\n",
            "    \"height\": 224,\n",
            "    \"width\": 224\n",
            "  },\n",
            "  \"do_center_crop\": true,\n",
            "  \"do_convert_rgb\": true,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.48145466,\n",
            "    0.4578275,\n",
            "    0.40821073\n",
            "  ],\n",
            "  \"image_processor_type\": \"CLIPImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.26862954,\n",
            "    0.26130258,\n",
            "    0.27577711\n",
            "  ],\n",
            "  \"resample\": 3,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"shortest_edge\": 224\n",
            "  }\n",
            "}\n",
            "\n",
            "- tokenizer: CLIPTokenizerFast(name_or_path='openai/clip-vit-base-patch16', vocab_size=49408, model_max_length=77, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t49406: AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
            "\t49407: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            ")\n",
            "\n",
            "{\n",
            "  \"processor_class\": \"CLIPProcessor\"\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_based_on_prompt(image_path, prompt, strength=0.75, guidance_scale = 7.5):\n",
        "  pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16,)\n",
        "  pipe = pipe.to(\"cuda\")\n",
        "  init_image = Image.open(image_path).convert(\"RGB\")\n",
        "  init_image = init_image.resize((512, 512))\n",
        "  modified_image = pipe(prompt=prompt, image=init_image, strength=strength, guidance_scale=guidance_scale).images[0]\n",
        "\n",
        "  return modified_image"
      ],
      "metadata": {
        "id": "jvJo4j-otz5e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a2494337a6c84aaeb62d8b63d3168321",
            "58ef86774768410f8e7d2764d03d87c2",
            "6967f74d3ec74b46b67a0efb15e6a3a2",
            "915db24e8afa405f98134f2580ea82a4",
            "f269fa190b0840edb95fad9c8fc88b71",
            "d2c8d3853d284b3db7285b905c8a1cdf",
            "9cf85325149b45d492c716e7a579bbfc",
            "dbd5935e5d1d4419a7f74a0dc7ef341f",
            "233a132ce6f14778a2b2390cc5bca3bd",
            "a9f99e99aac34405a3784354a7521a63",
            "a8479035352b4b19801f704859069e84",
            "14c7eebf9a5c4789bbd2eb07d2bda8a6",
            "3d6a27ef86a948c0b107560d3536d6d8",
            "36be9a304e2946f69d9132595f068369",
            "cd9b1b28edc546688d1017bfe6e67b14",
            "da63901213114aa0b635b71fa475acee",
            "37749776f23a49aa9aba2377b280deab",
            "6e30275963d74a879416cc9da148e3d7",
            "760782c16f3e4b079f12ffae242dcd99",
            "b273e2431ec34869a26c148dbbc89fc5",
            "20a2f915e5d3475eb80d9a81add95868",
            "4fc1f6d12fa443ba970682c2f5332010"
          ]
        },
        "collapsed": true,
        "id": "q1OLNstOxVjI",
        "outputId": "6aafb6f0-42a5-422d-885f-d7d03b7fdb31"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2494337a6c84aaeb62d8b63d3168321"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/feature_extractor/preprocessor_config.json\n",
            "size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}, {'max_height', 'max_width'}), got 224. Converted to {'shortest_edge': 224}.\n",
            "crop_size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}, {'max_height', 'max_width'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
            "Image processor CLIPImageProcessor {\n",
            "  \"crop_size\": {\n",
            "    \"height\": 224,\n",
            "    \"width\": 224\n",
            "  },\n",
            "  \"do_center_crop\": true,\n",
            "  \"do_convert_rgb\": true,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.48145466,\n",
            "    0.4578275,\n",
            "    0.40821073\n",
            "  ],\n",
            "  \"image_processor_type\": \"CLIPImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.26862954,\n",
            "    0.26130258,\n",
            "    0.27577711\n",
            "  ],\n",
            "  \"resample\": 3,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"shortest_edge\": 224\n",
            "  }\n",
            "}\n",
            "\n",
            "loading configuration file /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/text_encoder/config.json\n",
            "Model config CLIPTextConfig {\n",
            "  \"_name_or_path\": \"openai/clip-vit-large-patch14\",\n",
            "  \"architectures\": [\n",
            "    \"CLIPTextModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"dropout\": 0.0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"quick_gelu\",\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 77,\n",
            "  \"model_type\": \"clip_text_model\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"projection_dim\": 768,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"vocab_size\": 49408\n",
            "}\n",
            "\n",
            "loading weights file /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/text_encoder/model.safetensors\n",
            "Instantiating CLIPTextModel model under default dtype torch.float16.\n",
            "All model checkpoint weights were used when initializing CLIPTextModel.\n",
            "\n",
            "All the weights of CLIPTextModel were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/text_encoder.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use CLIPTextModel for predictions without further training.\n",
            "loading configuration file /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/safety_checker/config.json\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overridden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overridden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overridden.\n",
            "`text_config` is `None`. Initializing the `CLIPTextConfig` with default values.\n",
            "`vision_config` is `None`. initializing the `CLIPVisionConfig` with default values.\n",
            "Model config CLIPConfig {\n",
            "  \"_name_or_path\": \"CompVis/stable-diffusion-safety-checker\",\n",
            "  \"architectures\": [\n",
            "    \"StableDiffusionSafetyChecker\"\n",
            "  ],\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"logit_scale_init_value\": 2.6592,\n",
            "  \"model_type\": \"clip\",\n",
            "  \"projection_dim\": 768,\n",
            "  \"text_config\": {\n",
            "    \"dropout\": 0.0,\n",
            "    \"hidden_size\": 768,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"model_type\": \"clip_text_model\",\n",
            "    \"num_attention_heads\": 12\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"vision_config\": {\n",
            "    \"dropout\": 0.0,\n",
            "    \"hidden_size\": 1024,\n",
            "    \"intermediate_size\": 4096,\n",
            "    \"model_type\": \"clip_vision_model\",\n",
            "    \"num_attention_heads\": 16,\n",
            "    \"num_hidden_layers\": 24,\n",
            "    \"patch_size\": 14\n",
            "  }\n",
            "}\n",
            "\n",
            "loading weights file /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/safety_checker/model.safetensors\n",
            "Instantiating StableDiffusionSafetyChecker model under default dtype torch.float16.\n",
            "All model checkpoint weights were used when initializing StableDiffusionSafetyChecker.\n",
            "\n",
            "All the weights of StableDiffusionSafetyChecker were initialized from the model checkpoint at /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/safety_checker.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use StableDiffusionSafetyChecker for predictions without further training.\n",
            "loading file vocab.json\n",
            "loading file merges.txt\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading file tokenizer.json\n",
            "loading file chat_template.jinja\n",
            "ftfy or spacy is not installed using custom BasicTokenizer instead of ftfy.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/37 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14c7eebf9a5c4789bbd2eb07d2bda8a6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aV3UpCVxzP8Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}